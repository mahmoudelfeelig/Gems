name: Performance (Light)

on:
  workflow_dispatch:
  push:
    branches: [ "main" ]
  pull_request:
    types: [ opened, synchronize, reopened, labeled ]

permissions:
  contents: read

jobs:
  performance_light:
    name: performance-light
    # Run on demand, on main, or on PRs explicitly labeled "run-perf".
    if: >-
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'run-perf'))
    runs-on: ubuntu-latest
    timeout-minutes: 35

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache Gradle
        uses: actions/cache@v4
        with:
          path: |
            ~/.gradle/caches
            ~/.gradle/wrapper
            .gradle/loom-cache
          key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle*', 'gradle/wrapper/gradle-wrapper.properties') }}
          restore-keys: |
            ${{ runner.os }}-gradle-

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "21"

      - name: Set up Gradle
        uses: gradle/actions/setup-gradle@v3

      - name: Build
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f gradle/wrapper/gradle-wrapper.jar ]]; then
            chmod +x ./gradlew
            ./gradlew --no-daemon build
            exit 0
          fi

          echo "gradle-wrapper.jar is missing; bootstrapping Gradle from distributionUrl for CI..."
          url="$(grep -E '^distributionUrl=' gradle/wrapper/gradle-wrapper.properties | cut -d= -f2-)"
          curl -fsSL "$url" -o /tmp/gradle.zip
          unzip -q /tmp/gradle.zip -d /tmp/gradle
          gradle_bin="$(find /tmp/gradle -maxdepth 3 -type f -path '*/bin/gradle' | head -n1)"
          chmod +x "$gradle_bin"
          "$gradle_bin" --no-daemon build

      - name: Performance stress test (light)
        id: perf
        shell: bash
        run: |
          set -euo pipefail

          # Light run settings:
          # - 5 minutes spark profile, server thread only
          # - 5 minutes of your stress command
          PROFILE_SECONDS=300
          STRESS_SECONDS=300
          SNAPSHOT_TICKS=6000
          LAG_THRESHOLD_MS=51

          # Resolve a Gradle binary (wrapper if present, otherwise bootstrap).
          GRADLE="./gradlew"
          if [[ ! -f gradle/wrapper/gradle-wrapper.jar ]]; then
            url="$(grep -E '^distributionUrl=' gradle/wrapper/gradle-wrapper.properties | cut -d= -f2-)"
            curl -fsSL "$url" -o /tmp/gradle.zip
            unzip -q /tmp/gradle.zip -d /tmp/gradle
            GRADLE="$(find /tmp/gradle -maxdepth 3 -type f -path '*/bin/gradle' | head -n1)"
            chmod +x "$GRADLE"
          else
            chmod +x ./gradlew
          fi

          mkdir -p run/mods
          cat > run/eula.txt <<'EOF'
          eula=true
          EOF

          cat > run/server.properties <<'EOF'
          enable-rcon=true
          rcon.password=perf
          rcon.port=25575
          online-mode=false
          allow-flight=true
          # Shared CI runners can occasionally stall a tick during chunk work; relax watchdog.
          max-tick-time=300000
          view-distance=2
          simulation-distance=2
          spawn-protection=0
          max-players=50
          motd=gems-perf
          level-name=perfworld
          level-type=minecraft:flat
          sync-chunk-writes=false
          # Slow down autosaves to avoid periodic spikes; we'll manage saves manually in the run.
          max-auto-save-chunks-per-tick=8
          EOF

          CARPET_URL="$(python3 - <<'PY'
          import json
          import urllib.parse
          import urllib.request

          base = 'https://api.modrinth.com/v2/project/carpet/version'
          params = {
              'game_versions': json.dumps(['1.21.1']),
              'loaders': json.dumps(['fabric']),
          }
          url = base + '?' + urllib.parse.urlencode(params)
          req = urllib.request.Request(url, headers={'User-Agent': 'gems-perf-ci'})
          with urllib.request.urlopen(req) as r:
              data = json.loads(r.read().decode('utf-8'))
          if not data:
              raise SystemExit('No Carpet versions found for 1.21.1 + fabric')
          print(data[0]['files'][0]['url'])
          PY
          )"
          echo "Downloading Carpet: $CARPET_URL"
          curl -sSL "$CARPET_URL" -o run/mods/carpet.jar

          SPARK_URL="$(python3 - <<'PY'
          import json
          import urllib.parse
          import urllib.request

          def fetch_url(params):
              base = 'https://api.modrinth.com/v2/project/spark/version'
              url = base + '?' + urllib.parse.urlencode(params)
              req = urllib.request.Request(url, headers={'User-Agent': 'gems-perf-ci'})
              with urllib.request.urlopen(req) as r:
                  data = json.loads(r.read().decode('utf-8'))
              if not data:
                  return None
              for f in (data[0].get('files') or []):
                  if f.get('url'):
                      return f['url']
              return None

          url = fetch_url({'game_versions': json.dumps(['1.21.1']), 'loaders': json.dumps(['fabric'])})
          if url is None:
              url = fetch_url({'loaders': json.dumps(['fabric'])})
          print(url or '')
          PY
          )"
          if [[ -n "$SPARK_URL" ]]; then
            echo "Downloading spark: $SPARK_URL"
            curl -sSL "$SPARK_URL" -o run/mods/spark.jar
          else
            echo "spark download skipped (no matching version found)"
          fi

          "$GRADLE" --no-daemon runServer --args "nogui" > server.log 2>&1 &
          SERVER_PID=$!

          cleanup() {
            set +e
            if [[ -n "${SERVER_PID:-}" ]]; then
              echo "Stopping server..."
              python3 .github/rcon.py 127.0.0.1 25575 perf "stop" >/dev/null 2>&1 || true
              sleep 2 || true
              kill "$SERVER_PID" >/dev/null 2>&1 || true
              wait "$SERVER_PID" >/dev/null 2>&1 || true
            fi
            return 0
          }
          trap cleanup EXIT

          cat > .github/rcon.py <<'PY'
          import socket, struct, sys

          def _pkt(req_id: int, req_type: int, payload: str) -> bytes:
              data = payload.encode('utf-8') + b'\x00\x00'
              body = struct.pack('<ii', req_id, req_type) + data
              return struct.pack('<i', len(body)) + body

          def _recv(sock: socket.socket):
              raw_len = sock.recv(4)
              if len(raw_len) != 4:
                  raise RuntimeError('short read')
              (length,) = struct.unpack('<i', raw_len)
              raw = b''
              while len(raw) < length:
                  chunk = sock.recv(length - len(raw))
                  if not chunk:
                      break
                  raw += chunk
              if len(raw) != length:
                  raise RuntimeError('short packet')
              req_id, req_type = struct.unpack('<ii', raw[:8])
              payload = raw[8:-2].decode('utf-8', errors='replace')
              return req_id, req_type, payload

          def rcon(host: str, port: int, password: str, command: str) -> str:
              with socket.create_connection((host, port), timeout=2.0) as sock:
                  sock.sendall(_pkt(1, 3, password))  # login
                  rid, _, _ = _recv(sock)
                  if rid == -1:
                      raise SystemExit('RCON auth failed')
                  sock.sendall(_pkt(2, 2, command))  # command
                  out = []
                  # responses may be split; read until timeout
                  sock.settimeout(0.4)
                  while True:
                      try:
                          _, _, payload = _recv(sock)
                          out.append(payload)
                      except socket.timeout:
                          break
                  return ''.join(out).strip()

          if __name__ == '__main__':
              host = sys.argv[1]
              port = int(sys.argv[2])
              password = sys.argv[3]
              command = ' '.join(sys.argv[4:])
              print(rcon(host, port, password, command))
          PY

          echo "Waiting for RCON..."
          RCON_READY="false"
          for _ in $(seq 1 180); do
            if python3 .github/rcon.py 127.0.0.1 25575 perf "list" >/dev/null 2>&1; then
              RCON_READY="true"
              break
            fi
            sleep 1
          done
          if [[ "$RCON_READY" != "true" ]]; then
            echo "RCON never became ready; dumping server.log (last 200 lines):"
            tail -n 200 server.log || true
            echo "RCON never became ready; dumping run/logs/latest.log (last 200 lines):"
            tail -n 200 run/logs/latest.log || true
            exit 1
          fi

          rcon_raw() { python3 .github/rcon.py 127.0.0.1 25575 perf "$@"; }
          rcon() {
            # RCON can transiently fail under GC/IO pressure; retry a few times.
            local out rc
            for _ in $(seq 1 10); do
              out="$(rcon_raw "$@" 2>&1)"; rc=$?
              if [[ $rc -eq 0 ]]; then
                printf '%s\n' "$out"
                return 0
              fi
              if printf '%s' "$out" | grep -Eq 'ConnectionRefusedError|timed out|short read|short packet'; then
                sleep 1
                continue
              fi
              printf '%s\n' "$out" >&2
              return $rc
            done

            echo "RCON failed after retries; dumping server.log (last 200 lines):" >&2
            tail -n 200 server.log >&2 || true
            echo "RCON failed after retries; dumping run/logs/latest.log (last 200 lines):" >&2
            tail -n 200 run/logs/latest.log >&2 || true
            return 1
          }

          rcon "gamerule doMobSpawning false" || true
          rcon "gamerule doWeatherCycle false" || true
          rcon "gamerule randomTickSpeed 0" || true
          rcon "gamerule fallDamage false" || true
          rcon "save-off" || true
          rcon "gems admin perf reset"

          echo "Pregenerating / forceloading test areas..."
          rcon "forceload add -16 -16 16 16" || true
          rcon "execute in minecraft:the_nether run forceload add 34 34 66 66" || true
          rcon "execute in minecraft:the_end run forceload add -16 -16 16 16" || true
          rcon "forceload add 1984 784 2016 816" || true

          echo "Spawning Carpet bots..."
          spawn_overworld() {
            for i in $(seq 1 10); do
              x=$(( ( (i - 1) % 5 ) * 4 - 8 ))
              z=$(( ( (i - 1) / 5 ) * 4 - 2 ))
              rcon "execute positioned $x 80 $z run player bot$i spawn" >/dev/null 2>&1 || true
              sleep 0.05
            done
          }

          spawn_far_overworld() {
            for i in $(seq 1 10); do
              x=$((2000 + ( ( (i - 1) % 5 ) * 4 - 8 )))
              z=$((800 + ( ( (i - 1) / 5 ) * 4 - 2 )))
              rcon "execute positioned $x 80 $z run player far$i spawn" >/dev/null 2>&1 || true
              sleep 0.05
            done
          }

          spawn_nether() {
            for i in $(seq 1 10); do
              x=$((50 + ( ( (i - 1) % 5 ) * 3 - 6 )))
              z=$((50 + ( ( (i - 1) / 5 ) * 3 - 2 )))
              rcon "execute in minecraft:the_nether positioned $x 90 $z run player nether$i spawn" >/dev/null 2>&1 || true
              sleep 0.05
            done
          }

          spawn_end() {
            for i in $(seq 1 10); do
              x=$(( ( (i - 1) % 5 ) * 3 - 6 ))
              z=$(( ( (i - 1) / 5 ) * 3 - 2 ))
              rcon "execute in minecraft:the_end positioned $x 80 $z run player end$i spawn" >/dev/null 2>&1 || true
              sleep 0.05
            done
          }

          spawn_overworld
          spawn_far_overworld
          spawn_nether
          spawn_end

          rcon "gems admin setEnergy @a 10"
          rcon "gems admin resync @a"
          rcon "effect give @a minecraft:resistance 999999 4 true"

          echo "Settling chunks before profiling..."
          sleep 10
          rcon "gems admin perf reset"

          echo "Enabling spark tickmonitor (laggy tick reporting)..."
          rcon "spark tickmonitor --threshold-tick ${LAG_THRESHOLD_MS} --without-gc" || true

          # Start a 5-minute profile on the server thread only.
          SPARK_START_OUT="$(rcon "spark profiler start --timeout ${PROFILE_SECONDS} --thread \"Server thread\" --ignore-sleeping" 2>/dev/null || true)"
          if [[ -n "$SPARK_START_OUT" ]]; then
            echo "$SPARK_START_OUT"
          fi

          echo "Starting stress for ${STRESS_SECONDS}s..."
          rcon "gems admin stress start @a ${STRESS_SECONDS} 5 force true true"
          sleep $((STRESS_SECONDS + 10))

          OUT="$(rcon "gems admin perf snapshot ${SNAPSHOT_TICKS}" | tr -d '\r')"
          echo "$OUT"

          # Stop profiler explicitly (if timeout already ended it, this is harmless).
          SPARK_STOP_OUT="$(rcon "spark profiler stop --comment ci-light" 2>/dev/null || true)"
          if [[ -n "$SPARK_STOP_OUT" ]]; then
            echo "$SPARK_STOP_OUT"
          fi

          echo "Disabling spark tickmonitor..."
          rcon "spark tickmonitor" || true

          # Re-enable saves and flush once before shutdown.
          rcon "save-on" || true
          rcon "save-all flush" || true

          # Extract tickmonitor messages from logs into a dedicated artifact file.
          mkdir -p run
          LAG_FILE="run/laggy-ticks.txt"
          {
            echo "spark tickmonitor output (threshold-tick=${LAG_THRESHOLD_MS}ms)"
            echo
            # The exact wording can vary; this captures typical tickmonitor lines emitted by spark.
            grep -nE '\[spark\].*(Tick|tick)' run/logs/latest.log server.log 2>/dev/null || true
          } > "$LAG_FILE"
          if ! grep -qE '\[spark\].*(Tick|tick)' "$LAG_FILE"; then
            echo "No tickmonitor lines matched in logs." > "$LAG_FILE"
          fi

          export GEMS_PERF_OUT="$OUT"
          AVG_P95="$(python3 - <<'PY'
          import os
          import re

          s = os.environ.get("GEMS_PERF_OUT", "")
          m_avg = re.search(r"avg_mspt=([0-9]+(?:\\.[0-9]+)?)", s)
          m_p95 = re.search(r"p95_mspt=([0-9]+(?:\\.[0-9]+)?)", s)
          if not m_avg or not m_p95:
              raise SystemExit("Could not parse avg_mspt/p95_mspt from output")
          print(m_avg.group(1), m_p95.group(1))
          PY
          )"
          read -r AVG P95 <<<"$AVG_P95"
          echo "Parsed avg_mspt=$AVG p95_mspt=$P95"

          # Guardrails for regression detection (kept intentionally lenient for shared CI runners).
          awk -v avg="$AVG" -v p95="$P95" 'BEGIN{ exit !((avg+0) <= 40.0 && (p95+0) <= 120.0) }'

          # Print spark viewer link if present in the command output or logs.
          SPARK_LINK=""
          VIEWER_RE='https?://spark\.lucko\.me/[A-Za-z0-9]{6,}'
          SPARK_LINK="$(printf '%s\n' "${SPARK_STOP_OUT:-}" | grep -Eo "$VIEWER_RE" | tail -n1 || true)"
          if [[ -z "$SPARK_LINK" ]]; then
            SPARK_LINK="$(printf '%s\n' "${SPARK_START_OUT:-}" | grep -Eo "$VIEWER_RE" | tail -n1 || true)"
          fi
          if [[ -z "$SPARK_LINK" ]]; then
            for _ in $(seq 1 30); do
              SPARK_LINK="$(grep -Eo "$VIEWER_RE" server.log run/logs/latest.log 2>/dev/null | tail -n1 || true)"
              if [[ -n "$SPARK_LINK" ]]; then
                break
              fi
              sleep 1
            done
          fi
          SPARK_LINK="$(printf '%s' "$SPARK_LINK" | tr -d '\r')"
          if [[ -n "$SPARK_LINK" ]]; then
            echo "spark: $SPARK_LINK"
            echo "spark: $SPARK_LINK" >> server.log
          fi
          if [[ -n "${GITHUB_OUTPUT:-}" ]]; then
            echo "spark_link=${SPARK_LINK}" >> "$GITHUB_OUTPUT"
          fi
          if [[ -n "${GITHUB_STEP_SUMMARY:-}" ]]; then
            echo "### Performance (Light)" >> "$GITHUB_STEP_SUMMARY"
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "- Stress seconds: ${STRESS_SECONDS}" >> "$GITHUB_STEP_SUMMARY"
            echo "- Profile seconds: ${PROFILE_SECONDS} (Server thread only)" >> "$GITHUB_STEP_SUMMARY"
            echo "- avg_mspt: ${AVG}" >> "$GITHUB_STEP_SUMMARY"
            echo "- p95_mspt: ${P95}" >> "$GITHUB_STEP_SUMMARY"
            if [[ -n "$SPARK_LINK" ]]; then
              echo "- spark: ${SPARK_LINK}" >> "$GITHUB_STEP_SUMMARY"
            else
              echo "- spark: (no link found)" >> "$GITHUB_STEP_SUMMARY"
            fi
            LAG_COUNT="$(grep -cE '\[spark\].*(Tick|tick)' "$LAG_FILE" 2>/dev/null || true)"
            echo "- tickmonitor matches in logs: ${LAG_COUNT}" >> "$GITHUB_STEP_SUMMARY"
          fi

          if [[ -n "${KEEP_BOTS_PID:-}" ]]; then
            kill "$KEEP_BOTS_PID" >/dev/null 2>&1 || true
          fi
          cleanup
          trap - EXIT

      - name: Spark viewer link
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [[ -n "${{ steps.perf.outputs.spark_link }}" ]]; then
            echo "spark: ${{ steps.perf.outputs.spark_link }}"
            echo "spark: ${{ steps.perf.outputs.spark_link }}" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "spark: (no link found)"
          fi

      - name: Upload server log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-light-server-log
          path: server.log
          if-no-files-found: ignore

      - name: Upload spark output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-light-spark
          path: |
            run/spark/**
            run/logs/**
            run/laggy-ticks.txt
          if-no-files-found: ignore
